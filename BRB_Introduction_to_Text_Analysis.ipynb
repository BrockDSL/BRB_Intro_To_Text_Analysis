{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BRB Introduction to Text Analysis",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM90f60I0AsM/C7OlVpAVRy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrockDSL/BRB_Intro_To_Text_Analysis/blob/main/BRB_Introduction_to_Text_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![dsl_logo.png](https://raw.githubusercontent.com/BrockDSL/BRB_Intro_To_Text_Analysis/main/dsl_logo.png)\n",
        "\n",
        "# Introduction to Text Analysis\n",
        "## Buidling Better Research Workshop Series\n",
        "\n",
        "This workshop will introduce you to the basics of the what/how of harvesting social media information.\n",
        "\n",
        "\n",
        "## How this notebook works\n",
        "\n",
        "This webpage is a Google Colab notebook and is comprised of different *cells*. Some are code cells that run Python snippets. To works through these cells simply click on the triangle _run_ button in each cell.\n",
        "\n",
        "## Save a copy \n",
        "\n",
        "To save a copy of this notebook so you can return to it later please go to **File > Save Copy in Drive**"
      ],
      "metadata": {
        "id": "AzUolZCMmz3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code cell will load up all the required pieces to run our notebook.\n",
        "# Once you click into this cell you'll see a triangle 'play' button appear\n",
        "# Click on that to start your session\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('brown')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "%matplotlib inline\n",
        "print(\"Ready to proceed!\")"
      ],
      "metadata": {
        "id": "0gaZdVBJlQnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## EG. 1: Scrabble!\n",
        "\n",
        "Let's write some code the does the basics of text analysis in our Scrabble example."
      ],
      "metadata": {
        "id": "Fom3trE3s3Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will return the Scrabble score of a word\n",
        "# Click the play button to load this into memory\n",
        "\n",
        "def scrabble_score(word):\n",
        "    \n",
        "    #Dictionary of our scrabble scores\n",
        "    score_lookup = {\n",
        "        \"a\": 1,\n",
        "        \"b\": 3,\n",
        "        \"c\": 3,\n",
        "        \"d\": 2,\n",
        "        \"e\": 1,\n",
        "        \"f\": 4,\n",
        "        \"g\": 2,\n",
        "        \"h\": 4,\n",
        "        \"i\": 1,\n",
        "        \"j\": 8,\n",
        "        \"k\": 5,\n",
        "        \"l\": 1,\n",
        "        \"m\": 3,\n",
        "        \"n\": 1,\n",
        "        \"o\": 1,\n",
        "        \"p\": 3,\n",
        "        \"q\": 10,\n",
        "        \"r\": 1,\n",
        "        \"s\": 1,\n",
        "        \"t\": 1,\n",
        "        \"u\": 1,\n",
        "        \"v\": 4,\n",
        "        \"w\": 4,\n",
        "        \"x\": 8,\n",
        "        \"y\": 4,\n",
        "        \"z\": 10,\n",
        "        \"\\n\": 0, #just in case a new line character jumps in here\n",
        "        \" \":0 #normally single words don't have spaces but we'll put this here just in case\n",
        "        \n",
        "    }\n",
        "    \n",
        "    total_score = 0\n",
        "    \n",
        "    #We look up each letter in the scoring dictionary and add it to a running total\n",
        "    #to make our dictionary shorter we are just using lowercase letters so we need to\n",
        "    #change all of our input to lowercase with .lower()\n",
        "    for letter in word:\n",
        "        total_score = total_score + score_lookup[letter.lower()]\n",
        "    \n",
        "    return total_score"
      ],
      "metadata": {
        "id": "QNh9iH64s12i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: 1. Scrabble Fight ##\n",
        "\n",
        "Fill in values into the form below to experiement with different scrabble scores. Remember that you need to click the run button in both cells to update your results"
      ],
      "metadata": {
        "id": "kShJAhGnuQuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#@markdown Let's see who's name scores higher in Scrabble.\n",
        "your_name = \"Tim\" #@param {type:\"string\"}\n",
        "pets_name = \"Shorty\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Feel free to use something else if you don't have  pet.\n",
        "#@markdown Be sure hit the run button before moving on!\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t8m4PTQctM0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Score for my name is:\", scrabble_score(your_name))\n",
        "print(\"Score for my pet's name is:\",scrabble_score(pets_name))\n",
        "print(\"---\")\n",
        "\n",
        "if scrabble_score(pets_name) > scrabble_score(your_name):\n",
        "    print(\"My pet's name scores more points!\")\n",
        "else:\n",
        "    print(\"My name scores more (or the same) amount of points as my pets name\")"
      ],
      "metadata": {
        "id": "vP1RxeGkttae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Done!\n",
        "\n",
        "A simple example but it shows exactly what the steps are."
      ],
      "metadata": {
        "id": "42IiOM3zuDby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## EG. 2: A more interesting example\n",
        "\n",
        "\n",
        "Let's load up the tex of the diary of Winnie\n"
      ],
      "metadata": {
        "id": "5bQNjQTHuMuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "winnie_corpus = pd.read_csv('https://raw.githubusercontent.com/BrockDSL/Text_Analysis_with_Python/master/winnie_corpus.txt', header = None, delimiter=\"\\t\")\n",
        "winnie_corpus.columns = [\"page\",\"date\",\"entry\"]\n",
        "winnie_corpus['date'] = pd.to_datetime(winnie_corpus['date'])\n",
        "winnie_corpus['entry'] = winnie_corpus.entry.astype(str)\n",
        "\n",
        "#display our top 10 entries\n",
        "winnie_corpus.head()"
      ],
      "metadata": {
        "id": "7pikGDq8u3Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter sentiment\n",
        "\n",
        "We can analyze the _sentiment_ of the text (more [details](https://planspace.org/20150607-textblob_sentiment/)) The next cell demonstrates this:"
      ],
      "metadata": {
        "id": "ixMQ7UjbvWwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "happy_sentence = \"Python is the best programming language ever!\"\n",
        "sad_sentence = \"Python is difficult to use, and very frustrating\"\n",
        "\n",
        "\n",
        "print(\"Sentiment of happy sentence \", TextBlob(happy_sentence).sentiment)\n",
        "print(\"Sentiment of sad sentence \", TextBlob(sad_sentence).sentiment)\n",
        "\n",
        "# polarity ranges from -1 to 1.\n",
        "# subjectvity ranges from 0 to 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "44NovJt2u-rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: 2. Experimenting with Sentiment ##\n",
        "\n",
        "Try a couple of different sentences in the code cell below. See if you can create something that scores -1 and another that scores 1 for polarity. See if you can minimize the subjectivity of your sentence. Share your answers in the chat box."
      ],
      "metadata": {
        "id": "LM54a72evm1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"\"\"\n",
        "\n",
        "Just replace this sentence with some text!\n",
        "\n",
        "\"\"\"\n",
        "print(\"Score of test sentence is \", TextBlob(test_sentence).sentiment)"
      ],
      "metadata": {
        "id": "llHBl01pvwPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Sentiment to our Diary entries\n",
        "\n",
        "\n",
        "This next cell will score each diary entry in a new column that will be added to the dataframe. We loop through each entry, calculate the two scores that represent the sentiment. After all the scores are computed with add them to the dataframe."
      ],
      "metadata": {
        "id": "1r-QnPeLv3z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply sentiment analysis from TextBlob\n",
        "\n",
        "polarity = []\n",
        "subjectivity = []\n",
        "\n",
        "\n",
        "for day in winnie_corpus.entry:\n",
        "    #print(day,\"\\n\")\n",
        "    score = TextBlob(day)\n",
        "    polarity.append(score.sentiment.polarity)\n",
        "    subjectivity.append(score.sentiment.subjectivity)\n",
        "    \n",
        "winnie_corpus['polarity'] = polarity\n",
        "winnie_corpus['subjectivity'] = subjectivity\n",
        "\n",
        "\n",
        "#Let's look at our new top entries\n",
        "winnie_corpus.head()"
      ],
      "metadata": {
        "id": "LDh_AAPjv-tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph it out?\n",
        "\n",
        "Let's graph the changes in sentiment polarity to see what is happening with Winnie."
      ],
      "metadata": {
        "id": "u1HavhwZwH4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's graph out the sentiment as it changes day to day.\n",
        "\n",
        "plt.plot(winnie_corpus[\"date\"],winnie_corpus[\"polarity\"])\n",
        "plt.xticks(rotation='45')\n",
        "plt.title(\"Sentiment of Winnie's Diary Entries\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "03pzAQm6wFAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: 3. Interesting Spikes?\n",
        "\n",
        "We see some really strong negative and positive spikes in the sentiment. Let's just take a look at some of those entries. Run the next three cells to look at the individual negative and positive entries. Run the next couple of cell to see if we can isolate the _very positive_ and _very negative_ entries in the diary. "
      ],
      "metadata": {
        "id": "vptaXrNcwRaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instead of looking at just the hightest and lowest value we'll reduce that number by a threshold value\n",
        "#that way we can see numbers that are close to the highest sentiment and the lowest sentiment\n",
        "#we'll start with 20%.\n",
        "\n",
        "\n",
        "threshold = 0.2"
      ],
      "metadata": {
        "id": "5HMAPEupwXUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Very Negative\n",
        "bad_sentiment = winnie_corpus[\"polarity\"].min()\n",
        "\n",
        "#Reduce this number by threshold %\n",
        "bad_sentiment = bad_sentiment - (bad_sentiment * threshold)\n",
        "\n",
        "winnie_corpus[winnie_corpus[\"polarity\"] <= bad_sentiment]\n",
        "\n"
      ],
      "metadata": {
        "id": "LFYTDfIdwaai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Very Positive\n",
        "good_sentiment = winnie_corpus[\"polarity\"].max()\n",
        "\n",
        "#Reduce this number by threshold %\n",
        "good_sentiment = good_sentiment - (good_sentiment * threshold)\n",
        "\n",
        "winnie_corpus[winnie_corpus[\"polarity\"] >= good_sentiment]\n",
        "\n"
      ],
      "metadata": {
        "id": "i4jl57g6ws72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you think about the results of the _sentiment_ scoring. Do you agree with what constitutes a high score? How about a low score?"
      ],
      "metadata": {
        "id": "gmJOmGKmxDk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Noun Phrases for Automatic Keywork generation\n",
        "\n",
        "We can get a good idea about what a corpus is about by looking at the different nouns that show up in it. Nouns that show up a lot give us an idea of the contents of the text. Let's look at a random diary entry to see this in action"
      ],
      "metadata": {
        "id": "COfOx-jJzoNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_entry = winnie_corpus.sample(1)\n",
        "\n",
        "print(\"Total text of entry:\")\n",
        "print(random_entry[\"entry\"].values[0])\n",
        "\n",
        "\n",
        "print(\"\\nNow the noun phrases:\")\n",
        "entry_text = TextBlob(random_entry[\"entry\"].values[0])\n",
        "\n",
        "for np in entry_text.noun_phrases:\n",
        "  print(np)\n"
      ],
      "metadata": {
        "id": "gxjRtahAz4RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: 4. ##\n",
        "\n",
        "Let's see what Winnie talks about the most in first 6 months of the year. We can do this by extracting the noun phrases in her entries. We can put then put them into a frequency list and display them to the screen. Run the next week cells to build and display this information."
      ],
      "metadata": {
        "id": "uobEhdmk1eYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate all entries into different months by using the data column and extract noun phrases\n",
        "#by month\n",
        "\n",
        "#January Entries\n",
        "jan_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-01-01') & (winnie_corpus['date'] <= '1900-01-31')]\n",
        "jan_phrases = dict()\n",
        "\n",
        "for entry in jan_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in jan_phrases:\n",
        "            jan_phrases[np] += 1\n",
        "        else:\n",
        "            jan_phrases[np] = 1\n",
        "\n",
        "\n",
        "\n",
        "#February Entries\n",
        "feb_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-02-01') & (winnie_corpus['date'] <= '1900-02-28')]\n",
        "\n",
        "feb_phrases = dict()\n",
        "\n",
        "for entry in feb_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in feb_phrases:\n",
        "            feb_phrases[np] += 1\n",
        "        else:\n",
        "            feb_phrases[np] = 1\n",
        "\n",
        "#March Entries\n",
        "mar_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-03-01') & (winnie_corpus['date'] <= '1900-03-31')]\n",
        "\n",
        "\n",
        "mar_phrases = dict()\n",
        "\n",
        "for entry in mar_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in mar_phrases:\n",
        "            mar_phrases[np] += 1\n",
        "        else:\n",
        "            mar_phrases[np] = 1\n",
        "\n",
        "\n",
        "\n",
        "#April Entries\n",
        "april_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-04-01') & (winnie_corpus['date'] <= '1900-04-30')]\n",
        "\n",
        "april_phrases = dict()\n",
        "\n",
        "for entry in april_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in april_phrases:\n",
        "            april_phrases[np] += 1\n",
        "        else:\n",
        "            april_phrases[np] = 1\n",
        "\n",
        "#May Entries\n",
        "may_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-05-01') & (winnie_corpus['date'] <= '1900-05-31')]\n",
        "\n",
        "may_phrases = dict()\n",
        "\n",
        "for entry in may_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in may_phrases:\n",
        "            may_phrases[np] += 1\n",
        "        else:\n",
        "            may_phrases[np] = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#June Entries\n",
        "june_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-06-01') & (winnie_corpus['date'] <= '1900-06-30')]\n",
        "\n",
        "june_phrases = dict()\n",
        "\n",
        "for entry in june_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in june_phrases:\n",
        "            june_phrases[np] += 1\n",
        "        else:\n",
        "            june_phrases[np] = 1"
      ],
      "metadata": {
        "id": "OiWdJPMB1-Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We'll print the top ten noun phrases from each month below along with how many times they show up\n",
        "\n",
        "\n",
        "#Print the top 10 things she mentioned in January\n",
        "\n",
        "print(\"January\")\n",
        "for np in sorted(jan_phrases, key=jan_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, \">\",jan_phrases[np])\n",
        "\n",
        "print(\"\\nFebruary\")\n",
        "for np in sorted(feb_phrases, key=feb_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, \">\",feb_phrases[np])\n",
        "\n",
        "print(\"\\nMarch\")\n",
        "for np in sorted(mar_phrases, key=mar_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, mar_phrases[np])\n",
        "\n",
        "print(\"\\nApril\")\n",
        "#April Entries\n",
        "for np in sorted(april_phrases, key=april_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, april_phrases[np])\n",
        "\n",
        "print(\"\\nMay\")\n",
        "for np in sorted(may_phrases, key=may_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, may_phrases[np])\n",
        "\n",
        "print(\"\\nJune\")\n",
        "for np in sorted(june_phrases, key=june_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, june_phrases[np])"
      ],
      "metadata": {
        "id": "w7WTCT3A2duP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What can you say about Winnie's topics over the first half of the year? Share your thoughts in the chat box."
      ],
      "metadata": {
        "id": "bmHKNT9q2k9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Conclusion\n",
        "\n",
        "Text Analysis can go in many directions. The difficult part is usually getting your text ready. Once that is done there are many different venues to explore. Today will only looked a few basic examples of what can be done.\n",
        "\n",
        "If you're interested in exploring social media data for a research project or class please contact: **dsl @ brocku.ca** or checkout our the [DSL webpage](https://brocku.ca/library/dsl) for more details on how the Digital Scholarship Lab can help your research.\n",
        "\n"
      ],
      "metadata": {
        "id": "U9nFHKrq3u8Q"
      }
    }
  ]
}